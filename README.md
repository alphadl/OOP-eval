

# OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models.

### Benchmark

OOP is a Large Language Model (LLM) oop benchmark introduced in the paper "[OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2401.06628).". We collect code snippets from the [LeetCode](https://leetcode.com/), [open-source repositories on GitHub](https://github.com/), [Stack Overflow](https://stackoverflow.com/), [Codewars](https://www.codewars.com/) and are artificially processed. 

- It consists of 431 instances.
- It contains three difficulty levels:  Simple-level OOP, Moderate-level OOP, and
Difficult-level OOP.
- Please refer to the [OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models](https://arxiv.org/abs/2401.06628) for more details.


### Citations

Please cite the paper and star the repo if you use OOP and find it helpful.

Feel free to contact wangshuai123@whu.edu.cn or open an issue if you have any questions.

```latex
@article{wang2024oop,
  title={OOP: Object-Oriented Programming Evaluation Benchmark for Large Language Models},
  author={Wang, Shuai and Ding, Liang and Shen, Li and Luo, Yong and Du, Bo and Tao, Dacheng},
  journal={arXiv preprint arXiv:2401.06628},
  year={2024}
}
```
